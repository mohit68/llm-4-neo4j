{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Connected to Neo4j.\n",
      "ü§ñ Chatbot powered by LLaMA 3 (Groq API). Type 'exit' to quit.\n",
      "\n",
      "üí¨ Generating Cypher query...\n",
      "\n",
      "üìÑ Cypher Query:\n",
      " MATCH (se:SubmodelElement {idShort: 'TypeOfEmailAddress'}) RETURN se;\n",
      "\n",
      "üìä Query Results:\n",
      "{'se': {'smId': 'https://smartfactory.de/submodels/1b8b8375-73e6-4f37-9d7c-6d08e21b066f', 'idShort': 'TypeOfEmailAddress', 'idShortPath': 'ContactInformation.Email.TypeOfEmailAddress', 'value': '0173-1#07-AAS754#001'}}\n",
      "{'se': {'smId': 'https://smartfactory.de/submodels/1b8b8375-73e6-4f37-9d7c-6d08e21b066f', 'idShort': 'TypeOfEmailAddress', 'idShortPath': 'Address.Address.Email01.TypeOfEmailAddress', 'value': 'Office'}}\n",
      "üí¨ Generating Cypher query...\n",
      "\n",
      "üìÑ Cypher Query:\n",
      " MATCH (se:SubmodelElement {idShort: 'TypeOfEmailAddress'}) RETURN se;\n",
      "‚è© Skipped execution.\n",
      "üí¨ Generating Cypher query...\n",
      "\n",
      "üìÑ Cypher Query:\n",
      " MATCH (se:SubmodelElement {idShort: 'TypeOfEmailAddress'}) RETURN se;\n",
      "‚è© Skipped execution.\n",
      "üí¨ Generating Cypher query...\n",
      "\n",
      "üìÑ Cypher Query:\n",
      " MATCH (se:SubmodelElement {idShort: 'TypeOfEmailAddress'}) RETURN se;\n",
      "‚è© Skipped execution.\n",
      "üëã Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Neo4j connection (no auth)\n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"\"\n",
    "\n",
    "# creating a neo4j driver instance\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "\n",
    "# Groq + LLaMA 3 API config (set it in your env or paste directly here)\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\", \"Paste_your_key_here\")\n",
    "GROQ_API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "LLAMA_MODEL = \"llama3-70b-8192\"\n",
    "\n",
    "# getting schema from neo4j\n",
    "def get_graph_schema():\n",
    "    with driver.session() as session:\n",
    "        labels = set()\n",
    "        for record in session.run(\"MATCH (n) RETURN DISTINCT labels(n) AS labels\"):\n",
    "            for label in record[\"labels\"]:\n",
    "                labels.add(label)\n",
    "        rels = [r[\"relationshipType\"] for r in session.run(\"CALL db.relationshipTypes()\")]\n",
    "    return {\"labels\": list(labels), \"relationship_types\": rels}\n",
    "\n",
    "# Run Cypher query\n",
    "def run_cypher_query(query):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query)\n",
    "        return [record.data() for record in result]\n",
    "\n",
    "# Generate Cypher with context\n",
    "def generate_cypher_query(messages):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {GROQ_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": LLAMA_MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0,\n",
    "        \"max_tokens\": 300\n",
    "    }\n",
    "    response = requests.post(GROQ_API_URL, headers=headers, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "# Main chat loop\n",
    "def chat_bot():\n",
    "    print(\"üîó Connected to Neo4j.\")\n",
    "    print(\"ü§ñ Chatbot powered by LLaMA 3 (Groq API). Type 'exit' to quit.\\n\")\n",
    "    schema = get_graph_schema()\n",
    "\n",
    "    # Initial context messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"You are an assistant that converts natural language questions into Cypher queries for a Neo4j knowledge graph.\n",
    "\n",
    "Schema details:\n",
    "Labels: {schema['labels']}\n",
    "Relationship Types: {schema['relationship_types']}\n",
    "\n",
    "Only return Cypher queries. Do not explain.\"\"\"}\n",
    "    ]\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"\\nüß† Ask your question (or type 'exit'): \").strip()\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"üëã Goodbye!\")\n",
    "            break\n",
    "\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        print(\"üí¨ Generating Cypher query...\")\n",
    "        try:\n",
    "            cypher_query = generate_cypher_query(messages)\n",
    "            print(\"\\nüìÑ Cypher Query:\\n\", cypher_query)\n",
    "        except Exception as e:\n",
    "            print(\"‚ùå Error generating query:\", e)\n",
    "            continue\n",
    "\n",
    "        messages.append({\"role\": \"assistant\", \"content\": cypher_query})\n",
    "\n",
    "        run_it = input(\"‚ñ∂Ô∏è  Run this query? (y/n): \").strip().lower()\n",
    "        if run_it == \"y\":\n",
    "            try:\n",
    "                results = run_cypher_query(cypher_query)\n",
    "                print(\"\\nüìä Query Results:\")\n",
    "                for r in results:\n",
    "                    print(r)\n",
    "            except Exception as e:\n",
    "                print(\"‚ùå Error running query:\", e)\n",
    "        else:\n",
    "            print(\"‚è© Skipped execution.\")\n",
    "\n",
    "# Run the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    chat_bot()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
